\chapter{Event generation, simulation and reconstruction \label{chap:event_generation}}

\textcolor{red}{Outline to be finalized}

\section{What is an ``event''? \label{sec:event}}

% add picture of CMS event display
% add picture of hadronization etc for event

\section{Event generation \label{sec:event_generation}}

% add info on Madgraph, pythia, jet matching etc

\subsection{Matrix element generators}

\subsection{Parton shower and hadronization}

\subsection{Jet matching}


\section{Event simulation \label{sec:event_simulation}}

\subsection{CMS Full Simulation using Geant4 \label{subsec:fullsim}}

% add some info on how this is done, particle interaction with matter, ionization, 
% how it deals with long lived particles?

\subsection{CMS Fast Simulation \label{subsec:fastsim}}

% explain what approximations are made, why it is necessery, especially in SUSY searches

\section{Event reconstruction \label{sec:event_reconstruction}}

% Add subsection on each object with all the object definitions we use

% We select events with at least one interaction vertex, associated with at least 4 charged-particle
% tracks, that lies within 24~cm of the origin of the CMS coordinate system along the beam direction
% and 2~cm from the origin in the plane transverse to the beam. Owing to the high luminosity of the
% LHC, hard scattering events are typically accompanied by many additional events arising from the
% multiple proton-proton interactions that occur when the proton bunches cross.  The overlapping of
% events is referred to as pileup.  The primary vertex is identified as the vertex with the highest
% value of the $\sum \pt^2$ of the associated tracks.  Detector- and beam-related cleaning algorithms
% are used to remove events with detector noise that mimic events with high energy and large imbalance
% in transverse momentum.  


 

\subsection{Particle Flow technique \label{sec:event_reco_pf}}

% CMS reconstructs events using the particle flow (PF) method~\cite{PF}, which reconstructs particles
% (PF candidates) by combining information from the inner tracker, the calorimeters, and the muon
% system.  Each PF candidate is a ssigned to one of five object categories: muons, electrons, photons,
% charged hadrons, and neutral hadrons.  Contamination from pileup events is reduced by discarding
% charged PF candidates that are incompatible with having originated from the primary
% vertex~\cite{CMS-PAS-JME-14-001}.   The average pileup energy due to neutral hadrons is computed
% event-by-event and subtracted from the energy when computing lepton isolation and jet energy.  The
% energy subtracted is  the average pileup energy per unit area (in $\Delta\eta \times \Delta\phi$)
% times the jet area~\cite{Fastjet1, Fastjet2}.

\subsection{Object identification}

The event selection is an integral part of any physics analysis. It determines which events are
used, and thus what processes contribute to the data sample. This in turn drives how the
backgrounds are estimated, what the sensitivity will be, et cetera. 
An event selection is most easily described in terms of particles, e.g. two electrons, no muons, at
least four jets, as this is the closest to how we think about a given process.  
The particle flow technique is very compatible with this approach, given that it already
reconstructs particles out of the detector hits. 
However, a more thorough selection of the PF objects is needed in order to ensure that their
behaviour is understood, and to ensure that the selected events are not dominated by
misidentified particles, or detector artefacts. 
The physics object groups (POG's) within the CMS Collaboration are in charge of providing general
recommendations on how to define each object. 
In the following paragraphs all the standard objects that will be used in the razor boost analysis
will be discussed.

% 
% Missing transverse energy, which is used in the calculation of the razor variable $\mr$, is 
% defined to be the negative sum of the transverse momenta of all the particle flow objects in an
% event.  Loosely identified and isolated electrons with $\pt > 5$~\GeV and $|\eta| < 2.5$ and muons
% with $\pt > 5$\GeV and $|\eta| < 2.4$ are used both to suppress backgrounds in our signal region and
% in the definition of the control regions.  A tight definition of isolated leptons (electrons with
% $\pt > 10$~\GeV and $|\eta| < 2.5$ and muons with $\pt > 10$~\GeV and $|\eta| < 2.4$) defines a
% control region enriched in $\cPZ \rightarrow \ell \ell $ events, from which we estimate the
% systematic uncertainty in the predicted number of $\cPZ \rightarrow \nu \nu$ events in the signal
% region. Any electron candidates with $1.44 < |\eta| < 1.57$ are rejected since the transition region
% between barrel and endcap calorimeters is less well-instrumented.
% In order to suppress the decays of taus and other leptons that fail the loose selection, events that
% have isolated tracks with $\pt > 10$\GeV and track-primary vertex distance along the beam direction
% $dz < 0.05$ are rejected.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{event_objects.tex}



% \subsection{Pileup reweighting \label{sec:pileup}}
% 
% The distribution of the number of pileup interactions is different in Data vs MC. 
% As the number of pileup interactions can have an influence on various aspects of the reconstruction,
% we need to reweight the MC events to match the pileup distribution in data. 
% The method to do this is quite straightforward. 
% 
% \begin{enumerate}
% 
% \item Determine the pileup distribution in data by using a centrally provided script:
% {\footnotesize
% \begin{verbatim}
% pileupCalc.py -i Cert_190456-208686_8TeV_22Jan2013ReReco_Collisions12_JSON.txt 
%               -o data_pileup.root --inputLumiJSON=pileup_latest.txt 
%               --calcMode=true --minBiasXsec=69400 --maxPileupBin=100
% \end{verbatim}
% }
% In this, \texttt{pileup\_latest.txt} is taken directly from the central DQM area, as is the Lumi
% JSON. The Lumi JSON used is the one for the full Jan22 ReReco, corresponding to the data we are
% using, see section~\ref{sec:samples}. 
% 
% \item Determine the pileup distribution in simulation: \\ 
% For this we use a variable called \texttt{trueNumInteractions}. 
% The distribution of this variable for all MC events is used as the pileup distribution for Monte
% Carlo. 
% 
% \item Normalize the MC and data histograms to unit area, and divide them (Data/MC). The resulting
% histogram contains the event weights. 
% 
% \item Apply these event weights to each MC event, by picking up the value for
% \texttt{TrueNum\-Interactions} for that event, finding in what bin it falls and then applying the
% corresponding weight.
% 
% \end{enumerate}
% 
% The distribution of the pileup in data and simulation, and the corresponding pileup weight is shown
% in Figure~\ref{fig:DataMC_pileup} for the FullSim simulation and in figure~\ref{fig:DataMC_pileup52}
% for the FastSim simulation using CMSSW\_52X. 
% 
% \begin{figure}[p]
%  \centering
%  \includegraphics[width=0.7\textwidth]{figures/Pileup/compare_pileup_profile}
% \caption{Comparison plot of the true number of interactions in data and in MC. On the top the
% distribution of both are shown, on the bottom the ratio Data/MC. Left is linear scale, right is log
% scale. 
% \label{fig:DataMC_pileup}}
% \end{figure}
% 
% \begin{figure}[p]
%  \centering
%  \includegraphics[width=0.7\textwidth]{figures/Pileup/compare_pileup_profile_52X}
% \caption{Comparison plot of the true number of interactions in data and in MC processed with
% CMSSW\_52X. On the top the distribution of both are shown, on the bottom the ratio Data/MC. Left is
% linear scale, right is log scale. 
% \label{fig:DataMC_pileup52}}
% \end{figure}
% 
% As a test of the performance of the pileup reweighting, we can check the agreement between data and
% simulation for the distribution of the number of good primary vertices ($PV$) at different selection
% levels. 
% We expect to find a reasonable, although not perfect agreement as the vertex reconstruction
% efficiency depends on many things. 
% This comparison is shown in figure~\ref{fig:comparison_PV}. 
% 
% \begin{figure}
%  \includegraphics[width=0.49\textwidth]{figures/Pileup/DataMC_PV_0Lb1Ll}
%  \includegraphics[width=0.49\textwidth]{figures/Pileup/DataMC_PV_g1Mb1Ll}
% \caption{Data/MC comparison plot of the number of good primary vertices after pileup reweighting for
% a control region enhanced in $W+$jets (left) and enhanced in $t\bar{t}+$jets (right).
% \label{fig:comparison_PV}}
% \end{figure}


% \subsection[Top pt reweighting]{Top \pt reweighting \label{sec:toppt_reweighting}}
% 
% The TOP group has found in the normalized differential top-quark-pair cross section analysis that
% the shape of the \pt spectrum of the individual top quarks in data is softer than predicted by the
% various simulations while the available approx. NNLO prediction delivers a reasonable description.
% Based on this measurement, they have derived event scalefactors with associated systematic
% uncertainties to test the potential impact of the modelling of the top quark \pt spectrum
% \cite{TopPt}. 
% 
% The event weight is derived as a function of the generated \pt of both the top and anti-top quark in
% the event: 
% \begin{equation}
% w_{\textrm{TopPt}} = \sqrt{ SF_t * SF_{\bar{t}} }
% \end{equation}
% \begin{equation}
% SF(\pt^{gen}) = \exp(a + b \pt^{gen})
% \end{equation}
% with $a = 0.156$ and $b = -0.00137$.
% 
% The uncertainty on this reweighting is given by the following prescription: 
% \begin{align}
% +1~\sigma &: w = w_{\textrm{TopPt}} * w_{\textrm{TopPt}} \\
% -1~\sigma &: w = 1 
% \end{align}
% where $w$ is the weight to be applied to the event for the up/down variation. 
% 
% In figure~\ref{fig:TopPt} we show the Data/MC comparison for the $M_R$ and $R^2$ distribution in the
% $t\bar{t}+$jets control region (see section~\ref{sec:Tregion}) before and after applying the
% reweighting procedure. 
% We observe that this reweighting greatly improves the agreement between data and simulation. 
% Therefore we will always apply this reweighting to the $t\bar{t}+$jets simulated sample. 
% 
% \begin{figure}[htpb]
% \centering
% \includegraphics[width=0.49\textwidth]{
% figures/DataMC/DataMC_MR_g1Mbg1W1LlmT100_mdPhig0p5_width_noTopPt}
% \includegraphics[width=0.49\textwidth]{
% figures/DataMC/DataMC_R2_g1Mbg1W1LlmT100_mdPhig0p5_width_noTopPt}
% 
% \includegraphics[width=0.49\textwidth]{figures/DataMC/DataMC_MR_g1Mbg1W1LlmT100_mdPhig0p5_width}
% \includegraphics[width=0.49\textwidth]{figures/DataMC/DataMC_R2_g1Mbg1W1LlmT100_mdPhig0p5_width}
% \caption{[top] $M_R$ (left) and $R^2$ (right) distribution before applying the top \pt reweighting
%          [bottom] $M_R$ (left) and $R^2$ (right) distribution after applying the top \pt reweighting
% for the $T$ region as defined in section~\ref{sec:Tregion}
% \label{fig:TopPt}}
% \end{figure}

% 
% \subsection{ISR reweighting \label{sec:ISRreweighting}}
% 
% As recommended, we apply the ISR reweighting recipe developed in the SUSY group
% \cite{ISRreweighting} to all our simulated signal samples.
% Each event is reweighted with an event weight, depending on the \pt of the system that is recoiling
% against the ISR jet(s). 
% For the T1ttcc simplified model this system is the system of the two gluinos. For T2tt this is the
% system of the two stop squarks. 
% In table~\ref{tab:ISRreweighting} we list the scale factor to be applied for the different \pt
% ranges. 
% The difference between that scale factor and 1 is taken to be the one standard deviation
% uncertainty. 
% 
% \begin{table}[htpb]
% \centering
% \caption{ISR reweighting prescription \label{tab:ISRreweighting}}
% \begin{tabular}{|c|c|}
% \hline
% \pt of recoiling system & Scale factor \\ \hline
% $\leq 120$\GeV & 1 \\
% $120 - 150 $\GeV & 0.95 \\
% $150-250$\GeV & 0.9 \\
% $> 250$\GeV & 0.8 \\
% \hline
% \end{tabular}
% \end{table}

\subsection{Event Cleaning \label{sec:event_cleaning}}

The full CMS data taking and event reconstruction proces is very intricate. Every now and then a
subdetector might not have behaved properly, or a reconstruction algorithm could have failed. 
Events affected by such failures need to be removed from the selection, as they can for example
create artificially high missing transverse momentum.
The following cleaning filters are applied:

\begin{itemize}
\item The {\tt EcalDeadCellTriggerPrimitiveFilter}, which removes events where dead cells in the
ECAL produce anomalous activity.
\item The {\tt hcalLaserEventFilter}, which removes events where the HCAL laser produces anomalous
activity.
\item The {\tt hcalLaserEventFilter2012}, 
\item The {\tt trackingFailureFilter}, which removes events where the tracking algorithm does not
perform properly.
\item The {\tt CSCTightHaloFilter}, which removes events contaminated by beam halo.
\item The {\tt HBHENoiseFilter}, which removes events featuring large hadronic calorimeter noise.
\item The {\tt eeBadScFilter}, which removes events featuring high amplitude anomalous pulses due
to bad ECAL super-crystals.
\item The {\tt trkPOGFilters}, which remove events due to track reconstruction anomalies, such as
events with partly aborted track reconstruction and events affected by the Strip Tracker coherent
noise.
\item The {\tt primaryVertexFilter}, which removes events that do not have a good primary vertex.
\item The {\tt noscrapingFilter}, which removes events with a large multiplicity of low quality
tracks.
\end{itemize}

More details on these filters can be found in Ref.~\cite{metfilters}. The {\tt CSCTightHaloFilter}
and {\tt HBHENoiseFilter} filters are not applied for simulated samples that are
passed through the fast CMS detector simulation because the necessary input collections are
not produced.

In addition to the standard filters listed above, we also use an extra cleaning selection designed
to remove events with spurious HCAL noise originating in the Hadron Outer Calorimeter (HO). 
Energy deposits in the HO are included in the computation of the missing transverse momentum using 
the particle flow algorithm (PFMET), but are not included in the missing transverse energy obtained
from calorimeter information only (CaloMET). 
A selection requiring no substantial discrepancy between PFMET and CaloMET is thus effective at
reducing the contribution of these noisy events. 

We reject events in which the PFMET vector $\VEtmiss(\textrm{PF})$ is flipped with
respect to the CaloMET vector $\VEtmiss(\textrm{CALO})$. 
To accomplish this we compute the absolute value of the difference in polar angle,
 $|\Delta\phi_{\textrm{PF,CALO}}|$, taken in the range $[0,2\pi[$, and defined as
\begin{align}
|\Delta\phi_{\textrm{PF,CALO}}| &= \min \left ( \phi^{\textrm{PF}} - \phi^{\textrm{CALO}},   2\pi -
\phi^{\textrm{PF}} + \phi^{\textrm{CALO}} \right) ,\\
&\textrm{with } \phi^{\textrm{PF}} = \textrm{arctan} \left( \frac{\ETm(\textrm{PF})|_y}
{\ETm(\textrm{PF})|_x} \right) , \\
&\textrm{and } \phi^{\textrm{CALO}} = \textrm{arctan}\left( \frac{\ETm(\textrm{CALO})|_y}
{\ETm(\textrm{CALO})|_x} \right) .
\end{align}
Events for which $|\Delta\phi_{\textrm{PF,CALO}}|$ falls in a 1 radian window centred around $\pi$
are removed. 
\begin{equation}
\bigl| |\Delta\phi_{\textrm{PF,CALO}}| - \pi \bigr| < 1
\label{eqn:dphicut}
\end{equation}